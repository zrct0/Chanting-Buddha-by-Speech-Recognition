{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================准备训练：阿弥陀佛====================================\n",
      "=============================创建模型====================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (1, None, 256)            427008    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (1, None, 256)            525312    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (1, None, 1024)           263168    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 512)            524800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (1, None, 128)            65664     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (1, None, 1)              129       \n",
      "=================================================================\n",
      "Total params: 1,806,081\n",
      "Trainable params: 1,806,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#\"阿弥陀佛\", \"观世音菩萨\", \"观音菩萨\", \"南无阿弥陀佛\", \"南无观世音菩萨\"\n",
    "\n",
    "fohao_to_eng = {\"阿弥陀佛\":\"amtf\", \"观世音菩萨\":\"gsyps\", \"观音菩萨\":\"gyps\", \"南无阿弥陀佛\":\"nmamtf\", \"南无观世音菩萨\":\"nmgsyps\"}\n",
    "eng_to_fohao = {\"amtf\":\"阿弥陀佛\", \"gsyps\":\"观世音菩萨\", \"gyps\":\"观音菩萨\", \"nmamtf\":\"南无阿弥陀佛\", \"nmgsyps\":\"南无观世音菩萨\"}\n",
    "\n",
    "fohao_chinese = \"阿弥陀佛\"\n",
    "fohao = fohao_chinese\n",
    "#fohao =  = fohao_to_eng[fohao_chinese]\n",
    "MODEL_SAVE_PATH = r\"D:/语音识别/念佛计数/h5/\"\n",
    "#MODEL_SAVE_PATH = r\"./\"\n",
    "\n",
    "print(\"=============================准备训练：{}====================================\".format(fohao_chinese))\n",
    "#=================================================================\n",
    "\n",
    "def LoadCSV(path):    \n",
    "    with open(path) as csvfile: \n",
    "        reader = csv.reader(csvfile)\n",
    "        lx = []\n",
    "        ly = []\n",
    "        for row in reader:\n",
    "            lx.append(row[0:-1])\n",
    "            ly.append(row[-1])   \n",
    "        lx = np.reshape(lx, (-1, 5, 39)).astype(\"float32\")        \n",
    "        ly = np.array(ly).astype(\"float32\")        \n",
    "        print(\"load csv successed!:{0} \".format(path))\n",
    "    return lx, ly\n",
    "\n",
    "lstm_seq_length = 5\n",
    "dim = lstm_seq_length * 32\n",
    "\n",
    "def getData(path):\n",
    "    features, labels = LoadCSV(path)\n",
    "    features_expand = np.expand_dims(features, axis=-1)\n",
    "    rps = model_rec.predict(features_expand)    \n",
    "    \n",
    "    data_x, data_y = [], []\n",
    "    data_len = len(labels) - lstm_seq_length\n",
    "    for i in range(0, len(features) - lstm_seq_length):\n",
    "        data_x.append(np.reshape(rps[i:i+lstm_seq_length], (dim,)))  \n",
    "    data_x = np.expand_dims(data_x, axis=0)\n",
    "    data_y = np.reshape(labels[0:data_len], (1,data_len,1))   \n",
    "    print(\"create data shape x:{}, y:{}\".format(data_x.shape, data_y.shape))       \n",
    "    return data_x, data_y\n",
    "\n",
    "\n",
    "CSV_FILE_DIR = r\"D:/语音识别/念佛计数/语言模型CSV/{}/\".format(fohao)\n",
    "MODEL_REC_SAVEFILE_PATH = \"{}ACOUSTIC_32_MODEL_{}.h5\".format(r\"D:/语音识别/念佛计数/h5/\", fohao)\n",
    "model_rec = tf.keras.models.load_model(MODEL_REC_SAVEFILE_PATH)\n",
    "\n",
    "print(\"=============================创建模型====================================\")\n",
    "#=================================================================\n",
    "\n",
    "lstm_seq_length = 5\n",
    "dim = lstm_seq_length * 32\n",
    "\n",
    "model_ctor = tf.keras.Sequential()\n",
    "model_ctor.add(tf.keras.layers.LSTM(256, batch_input_shape=(1, None,dim), return_sequences=True, stateful=True))\n",
    "model_ctor.add(tf.keras.layers.LSTM(256, return_sequences=True, stateful=True))\n",
    "model_ctor.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model_ctor.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model_ctor.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model_ctor.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_ctor.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001), loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model_ctor.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "out_epoch:1/13\n",
      "load csv successed!:D:\\语音识别\\念佛计数\\语言模型CSV\\阿弥陀佛\\000_012.csv \n",
      "create data shape x:(1, 749, 160), y:(1, 749, 1)\n",
      "((1, 749, 160), (1, 749, 1))\n",
      "Train on 1 samples\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 5s 5s/sample - loss: 0.7048 - acc: 0.4860\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.6888 - acc: 0.4860\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.6766 - acc: 0.7810\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.6652 - acc: 0.8264\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.6534 - acc: 0.8198\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.6398 - acc: 0.8278\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.6253 - acc: 0.8571\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.6099 - acc: 0.8652\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.5933 - acc: 0.8718\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.5754 - acc: 0.8732\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.5565 - acc: 0.8732\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.5367 - acc: 0.8732\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.5159 - acc: 0.8732\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.4940 - acc: 0.8758\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.4713 - acc: 0.8758\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.4481 - acc: 0.8812\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.4247 - acc: 0.8879\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.4014 - acc: 0.8905\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.3787 - acc: 0.8892\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.3569 - acc: 0.8919\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.3363 - acc: 0.8959\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.3172 - acc: 0.8959\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.2997 - acc: 0.8959\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.2840 - acc: 0.8999\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.2702 - acc: 0.9012\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.2583 - acc: 0.8999\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.2481 - acc: 0.8985\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.2394 - acc: 0.9039\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.2319 - acc: 0.9052\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.2253 - acc: 0.9079\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.2193 - acc: 0.9119\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.2135 - acc: 0.9132\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.2078 - acc: 0.9146\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.2019 - acc: 0.9159\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.1959 - acc: 0.9199\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.1897 - acc: 0.9212\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.1834 - acc: 0.9266\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.1771 - acc: 0.9306\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.1709 - acc: 0.9332\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.1648 - acc: 0.9386\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.1591 - acc: 0.9453\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.1535 - acc: 0.9479\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.1481 - acc: 0.9506\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.1429 - acc: 0.9599\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.1379 - acc: 0.9586\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.1332 - acc: 0.9626\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.1286 - acc: 0.9573\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.1244 - acc: 0.9626\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.1188 - acc: 0.9626\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.1138 - acc: 0.9599\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.1093 - acc: 0.9653\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.1049 - acc: 0.9613\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.1004 - acc: 0.9680\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0949 - acc: 0.9666\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0906 - acc: 0.9720\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0865 - acc: 0.9760\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0820 - acc: 0.9746\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0774 - acc: 0.9800\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0720 - acc: 0.9813\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0677 - acc: 0.9826\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0638 - acc: 0.9826\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0600 - acc: 0.9866\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0566 - acc: 0.9880\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0518 - acc: 0.9880\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0474 - acc: 0.9907\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0433 - acc: 0.9907\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0406 - acc: 0.9920\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0380 - acc: 0.9920\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0343 - acc: 0.9933\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0308 - acc: 0.9960\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0281 - acc: 0.9973\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0264 - acc: 0.9973\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0240 - acc: 0.9973\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0212 - acc: 0.9987\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 3s 3s/sample - loss: 0.0195 - acc: 0.9973\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0179 - acc: 0.9987\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0156 - acc: 0.9987\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0143 - acc: 0.9973\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0129 - acc: 0.9987\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0112 - acc: 0.9987\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0104 - acc: 0.9987\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0084 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0068 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 3s 3s/sample - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 3s 3s/sample - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 96/100\n"
     ]
    }
   ],
   "source": [
    "out_epochs = 1\n",
    "epochs = 100\n",
    "\n",
    "csv_root = pathlib.Path(CSV_FILE_DIR)\n",
    "filelist = list(csv_root.glob(\"*\"))\n",
    "total_epochs = 1\n",
    "for oe in range(out_epochs):\n",
    "    random.shuffle(filelist)\n",
    "    for file in filelist:    \n",
    "        path = pathlib.Path(file)     \n",
    "        print(\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\")    \n",
    "        print(\"out_epoch:{}/{}\".format(total_epochs, len(filelist) * out_epochs))    \n",
    "        train_x, train_y  = getData(path)\n",
    "        print((train_x.shape, train_y.shape))\n",
    "        model_ctor.reset_states()\n",
    "        model_ctor.fit(train_x, train_y, epochs=epochs) \n",
    "        total_epochs += 1\n",
    "print(\"finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVEFILE_PATH = \"{}LANG_MODEL_{}.h5\".format(MODEL_SAVE_PATH, eng_to_fohao[fohao])\n",
    "model_ctor.save(MODEL_SAVEFILE_PATH)\n",
    "print(\"saved:{}\".format(MODEL_SAVEFILE_PATH))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
