{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert:D:\\语音识别\\念佛计数\\h5\\\\ACOUSTIC_MODEL_32_阿弥陀佛.h5\n",
      "convert:D:\\语音识别\\念佛计数\\h5\\\\ACOUSTIC_MODEL_32_观世音菩萨.h5\n",
      "convert:D:\\语音识别\\念佛计数\\h5\\\\ACOUSTIC_MODEL_32_观音菩萨.h5\n",
      "convert:D:\\语音识别\\念佛计数\\h5\\\\ACOUSTIC_MODEL_32_南无阿弥陀佛.h5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer #5 (named \"dense_8\"), weight <tf.Variable 'dense_8/kernel:0' shape=(256, 512) dtype=float32, numpy=\narray([[ 0.07261   ,  0.05197296, -0.00081185, ..., -0.08430767,\n        -0.03385974,  0.02377813],\n       [ 0.03985088, -0.03019548, -0.05468844, ...,  0.00638978,\n         0.0542736 ,  0.00263648],\n       [-0.02167752,  0.00635054,  0.01300205, ...,  0.02862125,\n        -0.02459555,  0.07087121],\n       ...,\n       [ 0.0570228 , -0.00345501,  0.08071319, ..., -0.01661212,\n        -0.05802053, -0.01049989],\n       [ 0.07255045, -0.05887999,  0.08830226, ...,  0.07497492,\n        -0.03013023,  0.06345282],\n       [ 0.05016052, -0.07864842, -0.02465384, ..., -0.05314098,\n        -0.00454653,  0.03091829]], dtype=float32)> has shape (256, 512), but the saved weight has shape (32, 7).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-94dad8e6b6cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mMODEL_SAVEFILE_PATH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"{}ACOUSTIC_MODEL_{}.h5\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"D:\\语音识别\\念佛计数\\h5\\\\\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfohao\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mMODEL_TO_SAVEFILE_PATH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"{}ACOUSTIC_MODEL_32_{}.h5\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"D:\\语音识别\\念佛计数\\h5\\\\\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfohao\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mmodel_rec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMODEL_SAVEFILE_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mmodel_rec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mmodel_rec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMODEL_TO_SAVEFILE_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name)\u001b[0m\n\u001b[0;32m    179\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[0;32m    180\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[1;32m--> 181\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name)\u001b[0m\n\u001b[0;32m   1173\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mby_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1175\u001b[1;33m         \u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1176\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group_by_name\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m    758\u001b[0m                                symbolic_weights[i])) +\n\u001b[0;32m    759\u001b[0m                            \u001b[1;34m', but the saved weight has shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 760\u001b[1;33m                            str(weight_values[i].shape) + '.')\n\u001b[0m\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Layer #5 (named \"dense_8\"), weight <tf.Variable 'dense_8/kernel:0' shape=(256, 512) dtype=float32, numpy=\narray([[ 0.07261   ,  0.05197296, -0.00081185, ..., -0.08430767,\n        -0.03385974,  0.02377813],\n       [ 0.03985088, -0.03019548, -0.05468844, ...,  0.00638978,\n         0.0542736 ,  0.00263648],\n       [-0.02167752,  0.00635054,  0.01300205, ...,  0.02862125,\n        -0.02459555,  0.07087121],\n       ...,\n       [ 0.0570228 , -0.00345501,  0.08071319, ..., -0.01661212,\n        -0.05802053, -0.01049989],\n       [ 0.07255045, -0.05887999,  0.08830226, ...,  0.07497492,\n        -0.03013023,  0.06345282],\n       [ 0.05016052, -0.07864842, -0.02465384, ..., -0.05314098,\n        -0.00454653,  0.03091829]], dtype=float32)> has shape (256, 512), but the saved weight has shape (32, 7)."
     ]
    }
   ],
   "source": [
    "fohao_list = [\"阿弥陀佛\", \"观世音菩萨\", \"观音菩萨\", \"南无阿弥陀佛\", \"南无观世音菩萨\"]\n",
    "\n",
    "for fohao in fohao_list:    \n",
    "    model_rec = tf.keras.Sequential()\n",
    "    model_rec.add(tf.keras.layers.Conv2D(256, (3,3), input_shape=(5,39,1), activation='relu'))\n",
    "    model_rec.add(tf.keras.layers.Conv2D(256, (3,3), activation='relu'))\n",
    "    model_rec.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "    model_rec.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "    model_rec.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "        \n",
    "    MODEL_SAVEFILE_PATH = \"{}ACOUSTIC_MODEL_{}.h5\".format(r\"D:\\语音识别\\念佛计数\\h5\\\\\", fohao)\n",
    "    MODEL_TO_SAVEFILE_PATH = \"{}ACOUSTIC_32_MODEL_{}.h5\".format(r\"D:\\语音识别\\念佛计数\\h5\\\\\", fohao)\n",
    "    model_rec.load_weights(MODEL_SAVEFILE_PATH, by_name=True)\n",
    "    model_rec.compile(optimizer=tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "    model_rec.save(MODEL_TO_SAVEFILE_PATH)\n",
    "    print(\"convert:{}\".format(MODEL_TO_SAVEFILE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert:D:\\语音识别\\念佛计数\\h5\\\\ACOUSTIC_MODEL_32_南无观世音菩萨.h5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "fohao = \"南无观世音菩萨\"\n",
    "\n",
    "model_rec = tf.keras.Sequential()\n",
    "model_rec.add(tf.keras.layers.Conv2D(256, (3,3), input_shape=(5,39,1), activation='relu'))\n",
    "model_rec.add(tf.keras.layers.Conv2D(256, (3,3), activation='relu'))\n",
    "model_rec.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "model_rec.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model_rec.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "\n",
    "MODEL_SAVEFILE_PATH = \"{}ACOUSTIC_MODEL_{}.h5\".format(r\"D:\\语音识别\\念佛计数\\h5\\\\\", fohao)\n",
    "MODEL_TO_SAVEFILE_PATH = \"{}ACOUSTIC_MODEL_32_{}.h5\".format(r\"D:\\语音识别\\念佛计数\\h5\\\\\", fohao)\n",
    "model_rec.load_weights(MODEL_SAVEFILE_PATH, by_name=True)\n",
    "model_rec.compile(optimizer=tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "model_rec.save(MODEL_TO_SAVEFILE_PATH)\n",
    "print(\"convert:{}\".format(MODEL_TO_SAVEFILE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
