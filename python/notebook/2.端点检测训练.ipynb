{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import wave\n",
    "import random\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_letter = 0\n",
    "end_letter = 11\n",
    "start_letter_asccii = start_letter\n",
    "end_letter_asccii = end_letter + 1\n",
    "letter_count = end_letter_asccii - start_letter_asccii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nchannels, sampwidth, framerate, nframes = None,None,None,None\n",
    "def decodeWav(wav):\n",
    "    global nchannels, sampwidth, framerate, nframes\n",
    "    wf = wave.open(wav, \"rb\")\n",
    "    nchannels, sampwidth, framerate, nframes = wf.getparams()[:4]\n",
    "    data = wf.readframes(nframes)\n",
    "    wf.close()\n",
    "    soundBytes = np.fromstring(data, dtype=np.int16)\n",
    "    soundBytes.shape = (-1, nchannels)\n",
    "    graph = soundBytes[:, 0]\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(wavPath):\n",
    "    soundBytes = decodeWav(wavPath)  \n",
    "    soundBytes = normalization(soundBytes)\n",
    "    return soundBytes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(soundBytes):\n",
    "    mean = soundBytes.mean()\n",
    "    std = soundBytes.std()\n",
    "    soundBytes = (soundBytes - mean)/std\n",
    "    return soundBytes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letter 0 has files count: 11\n",
      "letter 1 has files count: 3\n",
      "letter 2 has files count: 3\n",
      "letter 3 has files count: 3\n",
      "letter 4 has files count: 3\n",
      "letter 5 has files count: 3\n",
      "letter 6 has files count: 2\n",
      "letter 7 has files count: 2\n",
      "letter 8 has files count: 2\n",
      "letter 9 has files count: 2\n",
      "letter 10 has files count: 2\n",
      "letter 11 has files count: 2\n",
      "find 38 wave's files\n",
      "Feature extraction:2/38"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction:38/38\n",
      "Feature extraction finished\n"
     ]
    }
   ],
   "source": [
    "wavsPath = [] \n",
    "indexOfWavs = []\n",
    "decodeWavs = []\n",
    "labelOfWavs = [] \n",
    "seq_length = 1024\n",
    "\n",
    "wavs_folder = r'D:\\语音识别\\念佛计数\\端点检测训练集'\n",
    "file_count = 0\n",
    "\n",
    "for chrASCII in range(start_letter_asccii, end_letter_asccii):\n",
    "        for root, dirs, files in os.walk(wavs_folder + \"/\" + str(chrASCII)):    \n",
    "            print(\"letter {0} has files count: {1}\".format( str(chrASCII), len(files)))\n",
    "            file_count += len(files)\n",
    "print(\"find {0} wave's files\".format(file_count))\n",
    "\n",
    "index = 0\n",
    "for chrASCII in range(start_letter_asccii, end_letter_asccii):\n",
    "    for root, dirs, files in os.walk(wavs_folder + \"/\" + str(chrASCII)):\n",
    "        for file in files:\n",
    "            if os.path.splitext(file)[1].lower() == '.wav':\n",
    "                wavPath = os.path.join(root, file)\n",
    "                print(\"\\r\" + \"Feature extraction:{0}/{1}\".format(index, file_count), end=\"\", flush=True)\n",
    "                label = chrASCII - start_letter_asccii           \n",
    "                if label > 0:\n",
    "                    label = 1\n",
    "                decodeWavs.append(preprocessing(wavPath))\n",
    "                wavsPath.append(wavPath)   \n",
    "                labelOfWavs.append(label)\n",
    "                indexOfWavs.append(index)\n",
    "                index += 1\n",
    "print(\"\\r\" + \"Feature extraction:{0}/{1}\".format(index, file_count), end=\"\", flush=True)\n",
    "print(\"\\nFeature extraction finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "decodeWavs_count = len(decodeWavs)\n",
    "random.shuffle(indexOfWavs)\n",
    "seq_data_x = []\n",
    "seq_data_y = []\n",
    "for si in range(decodeWavs_count):\n",
    "    ix = indexOfWavs[si]\n",
    "    seq_data_x.extend(decodeWavs[ix])\n",
    "    seq_data_y.extend([labelOfWavs[ix]] * len(decodeWavs[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSamples(count):\n",
    "    set_x = []\n",
    "    set_y = []\n",
    "    for i in range(count):\n",
    "        frame = random.randint(0,len(seq_data_x) - 2 * seq_length)\n",
    "        set_x.append(seq_data_x[frame:frame + seq_length])\n",
    "        set_y.append(int(np.round(np.array(seq_data_y[frame + seq_length]).mean())))\n",
    "    set_x = np.expand_dims(set_x, axis=-1)\n",
    "    set_y = np.expand_dims(set_y, axis=-1)\n",
    "    print(\"set_x shape:{} ,set_y shape:{}\" .format(set_x.shape, set_y.shape))    \n",
    "    return set_x, set_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_x shape:(10000, 1024, 1) ,set_y shape:(10000, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<ZipDataset shapes: ((1024, 1), (1,)), types: (tf.float64, tf.int32)>,\n",
       " <ZipDataset shapes: ((1024, 1), (1,)), types: (tf.float64, tf.int32)>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_count = 10000\n",
    "data_x, data_y = getSamples(samples_count)\n",
    "split_boundary = int(0.8 * samples_count)\n",
    "train_x = data_x[:split_boundary]\n",
    "train_y = data_y[:split_boundary]\n",
    "test_x = data_x[split_boundary:]\n",
    "test_y = data_y[split_boundary:]\n",
    "\n",
    "train_count = np.shape(train_x)[0]\n",
    "test_count = np.shape(test_x)[0]\n",
    "\n",
    "tf_train_x = tf.data.Dataset.from_tensor_slices(train_x)\n",
    "tf_train_y = tf.data.Dataset.from_tensor_slices(train_y)\n",
    "tf_test_x = tf.data.Dataset.from_tensor_slices(test_x)\n",
    "tf_test_y = tf.data.Dataset.from_tensor_slices(test_y)\n",
    "tf_train_set = tf.data.Dataset.zip((tf_train_x, tf_train_y))\n",
    "tf_test_set = tf.data.Dataset.zip((tf_test_x, tf_test_y))\n",
    "(tf_train_set, tf_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "tf_train_set = tf_train_set.shuffle(samples_count).repeat().batch(batch_size)\n",
    "tf_test_set = tf_train_set.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 1022, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 511, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 509, 128)          24704     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 91,521\n",
      "Trainable params: 91,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv1D(64, (3,), input_shape=(1024,1), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool1D())\n",
    "model.add(tf.keras.layers.Conv1D(128, (3,), activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalAveragePooling1D())\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy', metrics=['acc'])\n",
    "steps_per_epoch = train_count//batch_size\n",
    "validation_steps = test_count//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 31 steps, validate for 7 steps\n",
      "Epoch 1/3\n",
      "31/31 [==============================] - 17s 540ms/step - loss: 0.1512 - acc: 0.9555 - val_loss: 0.1321 - val_acc: 0.9833\n",
      "Epoch 2/3\n",
      "31/31 [==============================] - 19s 617ms/step - loss: 0.1135 - acc: 0.9700 - val_loss: 0.0975 - val_acc: 0.9632\n",
      "Epoch 3/3\n",
      "31/31 [==============================] - 18s 574ms/step - loss: 0.0932 - acc: 0.9763 - val_loss: 0.1300 - val_acc: 0.9743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x505dd1c8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tf_train_set, epochs=3, steps_per_epoch=steps_per_epoch, validation_data=tf_train_set, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = r\"D:\\语音识别\\念佛计数\\h5\\PFB_EndPointDetect.h5\"\n",
    "model.save(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = r\"D:\\语音识别\\念佛计数\\PFB_EndPointDetect.h5\"\n",
    "model = tf.keras.models.load_model(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "RECORD_SECONDS = 100\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epd_predict(data, seq_length):\n",
    "    soundBytes = np.fromstring(np.array(data), dtype=np.int16)\n",
    "    nsb = normalization(soundBytes).reshape(1,seq_length,1)   \n",
    "    epd = int(np.round(model.predict(nsb)))    \n",
    "    return epd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始录音\n",
      "0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000000000000000000000111111111111111110000000001111111000111111111111101111110011111111111111111111111111101110000011111111111111011111001111111100000001111111111111111111111001111111111111"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-72aa10efcd2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRATE\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mCHUNK\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mRECORD_SECONDS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCHUNK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepd_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"结束录音\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-fe8125eed083>\u001b[0m in \u001b[0;36mepd_predict\u001b[1;34m(data, seq_length)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0msoundBytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mnsb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoundBytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mepd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnsb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mepd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    460\u001b[0m     return self._model_iteration(\n\u001b[0;32m    461\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m         steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[1;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    412\u001b[0m           model, mode)\n\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m       \u001b[0mdata_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m       callbacks = cbks.configure_callbacks(\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    330\u001b[0m     if (context.executing_eagerly()\n\u001b[0;32m    331\u001b[0m         or ops.get_default_graph()._building_function):  # pylint: disable=protected-access\n\u001b[1;32m--> 332\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIteratorV2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    591\u001b[0m           context.context().device_spec.device_type != \"CPU\"):\n\u001b[0;32m    592\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/cpu:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    608\u001b[0m           gen_dataset_ops.anonymous_iterator_v2(\n\u001b[0;32m    609\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m               output_shapes=self._flat_output_shapes))\n\u001b[0m\u001b[0;32m    611\u001b[0m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m       \u001b[1;31m# Delete the resource when this object is deleted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36manonymous_iterator_v2\u001b[1;34m(output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[1;34m\"AnonymousIteratorV2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         \"output_types\", output_types, \"output_shapes\", output_shapes)\n\u001b[0m\u001b[0;32m    143\u001b[0m       \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_AnonymousIteratorV2Output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"开始录音\")\n",
    "for t in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)    \n",
    "    print(epd_predict(data, seq_length), end=\"\")  \n",
    "print(\"结束录音\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
