{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from python_speech_features import *\n",
    "import os\n",
    "import wave\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavs_folder = r'D:\\语音识别\\念佛计数\\单字训练集1'\n",
    "#wavs_folder = r'../input/pfb-recognition-train/single_world_train_1'\n",
    "MODEL_SAVE_PATH = r\"./\"\n",
    "word_to_id = {'阿':0,'弥':1,'陀':2,'佛':3,'南':4,'无':5,'观':6,'世':7,'音':8,'菩':9,'萨':10}\n",
    "train_epochs = 100\n",
    "\n",
    "select_word = \"观音菩萨\"\n",
    "select_id = [word_to_id[x] for x in select_word]\n",
    "letter_count = len(select_id)\n",
    "print(\"准备训练:{}\".format(select_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nchannels, sampwidth, framerate, nframes = None,None,None,None\n",
    "def decodeWavByPath(wavPath):\n",
    "    global nchannels, sampwidth, framerate, nframes\n",
    "    wf = wave.open(wavPath, \"rb\")\n",
    "    nchannels, sampwidth, framerate, nframes = wf.getparams()[:4]\n",
    "    data = wf.readframes(nframes)\n",
    "    wf.close()\n",
    "    soundBytes = np.fromstring(data, dtype=np.int16)\n",
    "    soundBytes.shape = (-1, nchannels)\n",
    "    graph = soundBytes[:, 0]\n",
    "    return graph\n",
    "\n",
    "def preprocessing(soundBytes):\n",
    "    soundBytes = (soundBytes - soundBytes.mean())/soundBytes.std()\n",
    "    mfcc_feat0 =  mfcc(soundBytes)\n",
    "    mfcc_feat1 = delta(mfcc_feat0, 1)\n",
    "    mfcc_feat2 = delta(mfcc_feat0, 2)    \n",
    "    feature = np.hstack((mfcc_feat0, mfcc_feat1, mfcc_feat2))\n",
    "    return feature\n",
    "\n",
    "print(\"=========================读取声音文件========================================\")\n",
    "#=================================================================\n",
    "\n",
    "wavsPath = [] \n",
    "indexOfWavs = []\n",
    "decodeWavs = []\n",
    "labelOfWavs = []\n",
    "\n",
    "file_count = 0\n",
    "\n",
    "for wordId in select_id:    \n",
    "    for root, dirs, files in os.walk(wavs_folder + \"/\" + str(wordId)):    \n",
    "        print(\"letter {0} has files count: {1}\".format( str(wordId), len(files)))\n",
    "        file_count += len(files)\n",
    "print(\"find {0} wave's files\".format(file_count))\n",
    "\n",
    "index = 0\n",
    "range_id = 0\n",
    "for wordId in select_id:     \n",
    "    for root, dirs, files in os.walk(wavs_folder + \"/\" + str(wordId)):\n",
    "        for file in files:\n",
    "            if os.path.splitext(file)[1].lower() == '.wav':\n",
    "                wavPath = os.path.join(root, file)\n",
    "                print(\"\\r\" + \"Feature extraction:{0}/{1}\".format(index, file_count), end=\"\", flush=True)\n",
    "                label = range_id  \n",
    "                decodeWavs.append(decodeWavByPath(wavPath))\n",
    "                wavsPath.append(wavPath)   \n",
    "                labelOfWavs.append(label)\n",
    "                indexOfWavs.append(index)\n",
    "                index += 1\n",
    "    range_id += 1\n",
    "print(\"\\r\" + \"Feature extraction:{0}/{1}\".format(index, file_count), end=\"\", flush=True)\n",
    "print(\"\\nFeature extraction finished\")\n",
    "\n",
    "print(\"============================预处理=====================================\")\n",
    "#=================================================================\n",
    "\n",
    "seq_length = 1024\n",
    "divWavs = []\n",
    "divLabel = []\n",
    "\n",
    "def divWav1024(soundBytes, label):\n",
    "    n = (len(soundBytes) // seq_length)\n",
    "    cd_soundBytes = soundBytes[0: n * seq_length]\n",
    "    cd_soundBytes = np.reshape(cd_soundBytes, (n,seq_length ))\n",
    "    cd_label = [label] * n  \n",
    "    return cd_soundBytes, cd_label\n",
    "    \n",
    "for ix in range(len(decodeWavs)):    \n",
    "    print(\"\\r\" + \"Div wav to seq length:{0}/{1}\".format(ix, file_count), end=\"\", flush=True)\n",
    "    cd_soundBytes, cd_label = divWav1024(decodeWavs[ix], labelOfWavs[ix])\n",
    "    divWavs.extend(cd_soundBytes)  \n",
    "    divLabel.extend(cd_label)   \n",
    "\n",
    "proprocessed_wavs = [preprocessing(x) for x in divWavs]\n",
    "print(\"\\ndivWavs shape:\", np.shape(divWavs))\n",
    "print(\"proprocessed_wavs shape:\", np.shape(proprocessed_wavs))\n",
    "print(\"divLabel shape:\", np.shape(divLabel))\n",
    "\n",
    "set_x = np.expand_dims(proprocessed_wavs, axis=-1)\n",
    "set_y = np.expand_dims(divLabel, axis=-1)\n",
    "print(\"set_x shape:{} ,set_y shape:{}\" .format(set_x.shape, set_y.shape)) \n",
    "\n",
    "print(\"=============================加载到tf.data====================================\")\n",
    "#=================================================================\n",
    "\n",
    "samples_count = set_y.shape[0]\n",
    "split_boundary = int(0.8 * samples_count)\n",
    "train_x = set_x[:split_boundary]\n",
    "train_y = set_y[:split_boundary]\n",
    "test_x = set_x[split_boundary:]\n",
    "test_y = set_y[split_boundary:]\n",
    "\n",
    "train_count = np.shape(train_x)[0]\n",
    "test_count = np.shape(test_x)[0]\n",
    "\n",
    "tf_train_x = tf.data.Dataset.from_tensor_slices(train_x)\n",
    "tf_train_y = tf.data.Dataset.from_tensor_slices(train_y)\n",
    "tf_test_x = tf.data.Dataset.from_tensor_slices(test_x)\n",
    "tf_test_y = tf.data.Dataset.from_tensor_slices(test_y)\n",
    "tf_train_set = tf.data.Dataset.zip((tf_train_x, tf_train_y))\n",
    "tf_test_set = tf.data.Dataset.zip((tf_test_x, tf_test_y))\n",
    "print((tf_train_set, tf_test_set))\n",
    "\n",
    "batch_size = 50\n",
    "tf_train_set = tf_train_set.shuffle(samples_count).repeat().batch(batch_size)\n",
    "tf_test_set = tf_train_set.batch(batch_size)\n",
    "steps_per_epoch = train_count//batch_size\n",
    "validation_steps = test_count//batch_size\n",
    "\n",
    "steps_per_epoch = train_count//batch_size\n",
    "validation_steps = test_count//batch_size\n",
    "\n",
    "print(\"=============================创建模型====================================\")\n",
    "#=================================================================\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(256, (3,3), input_shape=(5,39,1), activation='relu'))\n",
    "model.add(tf.keras.layers.Conv2D(256, (3,3), activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(letter_count, activation='softmax'))\n",
    "print(model.summary())\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "print(\"=============================开始训练====================================\")\n",
    "#=================================================================\n",
    "history = model.fit(tf_train_set, epochs=train_epochs, steps_per_epoch=steps_per_epoch, validation_data=tf_train_set, validation_steps=validation_steps)\n",
    "\n",
    "print(\"=========================保存模型========================================\")\n",
    "#=================================================================\n",
    "\n",
    "MODEL_SAVEFILE_PATH = \"{}ACOUSTIC_MODEL_{}.h5\".format(MODEL_SAVE_PATH, select_word)\n",
    "model.save(MODEL_SAVEFILE_PATH)\n",
    "print(\"saved:{}\".format(MODEL_SAVEFILE_PATH))\n",
    "\n",
    "print(\"=========================画出损失函数========================================\")\n",
    "#=================================================================\n",
    "\n",
    "plt.plot(range(len(history.history[\"acc\"])), history.history[\"acc\"], color='r')\n",
    "plt.plot(range(len(history.history[\"val_acc\"])), history.history[\"val_acc\"], color='g')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
